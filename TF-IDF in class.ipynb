{
 "metadata": {
  "name": "",
  "signature": "sha256:f38074bef922758914a7b72b27166d8a980fb7918e220f86334346a378b17bd4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TF-IDF: If you have a term that's located in one doc out of the entire corpus, the IDF multiplier will be larger."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "names = nltk.corpus.gutenberg.fileids()\n",
      "texts = [nltk.corpus.gutenberg.raw(fileid) for fileid in names]\n",
      "len(texts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "18"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "documentation [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
      "\n",
      "min_df: float in range 0-1, would be a ratio of docus the term has to occur in. Or, an integer like min_df = 3, would mean the term has to appear in 3 docs to be counted."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidfVectorizer = TfidfVectorizer(stop_words='english', min_df=2) # lower case first letter = variable; capital = type of class\n",
      "\n",
      "tfidfVector = tfidfVectorizer.fit_transform(texts)\n",
      "\n",
      "tfidfVector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "<18x19400 sparse matrix of type '<class 'numpy.float64'>'\n",
        "\twith 94890 stored elements in Compressed Sparse Row format>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sparse matrix = only 94890 cells with information/ non zero.\n",
      "'numpy.float64' = the class of this matrix.  \n",
      "\n",
      "Can make a data frame from a numpy array. Pandas are enveloppes for them that allow more manipulation and functions to be used. First, we hvae to convert the sparse matrix to an array. While they are the effectively the same, we need to 'fill in the zeroes'. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "terms = tfidfVectorizer.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "tfidfMatrix = pd.DataFrame(tfidfVector.toarray(), index=names, columns=terms)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "documentTopTerms = [] # for each document we want the top few terms\n",
      "for name, series in tfidfMatrix.iterrows(): # gives a tuple of(name/index, series -- a data type in panda which has cool uses)\n",
      "    # each row of values, the series, is sorted alphabetically; we want to reorder them by highest value\n",
      "    series.order(ascending=False, inplace=True) # inplace not only returns a value, but modifies the tfidfMatrix\n",
      "    for term, tfidf in series[0:10].iteritems():\n",
      "        documentTopTerms.append((name, term, tfidf))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topTermsDF = pd.DataFrame(documentTopTerms, columns=[\"File\", \"Term\", \"tf-idf\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## How can I output this for other programs to use?\n",
      "topTermsDF.to_csv(\"gutenbergTopTerms.csv\", index=False) #index=False will get rid of the first numbers/index\n",
      "# \"...csv\" will save it as a file in the same directory as the notebook. you should then be able to find it and open it. "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can use the csv output in something like [raw density](http://raw.densitydesign.org/)\n",
      "\n",
      "Look up panda series class manipulations for more information. you can get the median/mean values, sorting, etc. If you have texts chronologically listed, and they're in order of their printing, one of the things you can do is to look at 'kurtosis' a way of measuring how the values change/the slope of the change.\n",
      "With the dataframes, you can use 'corr' to find correlation values between series or everything."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}