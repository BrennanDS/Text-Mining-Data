{
 "metadata": {
  "name": "",
  "signature": "sha256:eeca9100427cad76a5deb9c72d81b47adf7ea78f8b52d857ff3f8df4f6e9da81"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Next Steps:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "What's the count of \"bug\" in our ```goldBugWordTokens``` list and of \"bug word\" in our ```goldBugLemmasForBugs``` list?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As always, we'll have to start with our standard operations of retrieving the locally stored text and then tokenize it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read Gold Bug plain text into string\n",
      "f = open(\"data/goldBug.txt\", \"r\")\n",
      "goldBugString = f.read()\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "goldBugTokens = nltk.word_tokenize(goldBugString)\n",
      "goldBugWordTokens = [word for word in goldBugTokens if any(c.isalpha() for c in word)]\n",
      "goldBugWordTokensLowercase = [word.lower() for word in goldBugWordTokens]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we'll ge the count of 'bug' from our lower case tokens list:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bugTokenCount = goldBugWordTokensLowercase.count(\"bug\")\n",
      "bugStringCount = goldBugString.lower().count(\"bug\")\n",
      "print(\"'bug' in Tokens: \", bugTokenCount, \"\\n'bug' in String: \", bugStringCount)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "'bug' in Tokens:  32 \n",
        "'bug' in String:  38\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, in order to make a 'bug word' grouping of related words,  we'll first have to lemmatize our text/tokens:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.stem import WordNetLemmatizer\n",
      "wnl = WordNetLemmatizer()\n",
      "goldBugLemmas = [wnl.lemmatize(word) for word in goldBugWordTokens]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then we'll try to find our related words, by using hyponym's of 'bug' (as we saw in the workbook, we'll be taking the ```bug.n.01``` synset) and bug's hypernym, insect."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import wordnet as wn\n",
      "bugSynset = wn.synset(\"bug.n.01\")\n",
      "print(bugSynset, bugSynset.definition())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Synset('bug.n.01') general term for any insect or similar creeping or crawling invertebrate\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This next cell is copied from the workbook as a function used to collect all of the possibly related words to 'bug':"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def collect_hyponym_lemma_names(synset, hyponynm_names):\n",
      "    for hyponym in synset.hyponyms(): # go through this synset's hyponyms\n",
      "        for lemma in hyponym.lemmas(): # go through each hyponym's lemma\n",
      "            hyponynm_names.append(lemma.name()) # add this lemma name to our list\n",
      "        collect_hyponym_lemma_names(hyponym, hyponynm_names) # this this hyponym's hyponyms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_hyponym_names_from_hypernym(synset):\n",
      "    names = []\n",
      "    for hypernym in synset.hypernyms():\n",
      "        collect_hyponym_lemma_names(hypernym, names)\n",
      "    return sorted(set(names))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's put those functions to action and grab ourselves the bug hyponyms:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bug_hypernym_hyponyms = get_hyponym_names_from_hypernym(bugSynset)\n",
      "print(bugSynset, \"has\", len(bug_hypernym_hyponyms), \"hyponyms\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Synset('bug.n.01') has 886 hyponyms\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But not all of these are useful to us -- they don't all appear in Poe's story. Here we'll then find a list of related bug words that ARE relevant to our text (again, we already know that the word 'soldier' ought to be omitted from this list):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bugRelatedWords = list(set([word for word in goldBugLemmas if word in bug_hypernym_hyponyms]))\n",
      "bugRelatedWords\n",
      "bugRelatedWordsFiltered = [word for word in bugRelatedWords if \"soldier\" not in word]\n",
      "bugRelatedWordsFiltered"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "['beetle', 'bee', 'bug', 'scarabaeus']"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll use these filtered words to form a 'bug word' variable (I'm actually unsure of what to call this object, exactly. And, for that matter, how to use it outside of 'goldBugLemmasForBugs'. Is it a localized variable only used in that list, like a kind of sublist?) to use in relation to the grouping of lemmas as a whole. From there we can get the two counts we sough out at the start:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "goldBugLemmasForBugs = [\"bug word\" if word in bugRelatedWordsFiltered else word for word in goldBugLemmas]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bugWordLemmaCount = goldBugLemmasForBugs.count(\"bug word\")\n",
      "print(\"The number of occurences of bug-like words in our lemma list is: \", bugWordLemmaCount, \"\\nThe number of occurences of 'bug' in our token list is: \", bugTokenCount)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The number of occurences of bug-like words in our lemma list is:  56 \n",
        "The number of occurences of 'bug' in our token list is:  32\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "What's the percentage increase in coverage that we get by lemmatizing and looking related words using WordNet?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll calculate the percentage increase by taking the difference between the two numbers, dividing the new value by the first 'bug' count, and multiplying by 100."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "differenceBetweenBugCounts = bugWordLemmaCount - bugTokenCount\n",
      "percentageIncreaseOfBugCounts = (differenceBetweenBugCounts/bugTokenCount)*100\n",
      "print(\"By using hyponyms and hypernyms we were able to find \", percentageIncreaseOfBugCounts, \"% more occurences of (according to WordNet) bug related words!\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "By using hyponyms and hypernyms we were able to find  75.0 % more occurences of (according to WordNet) bug related words!\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "What's another word in The Gold Bug where the percentage increase is greater using the same process we followed:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I'm not sure of how wel this will work, given that it's a verb, but I'm going to first try to use the word 'said', which we've already seen to be a rather common word."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for synset in wn.synsets(\"said\"):\n",
      "     print(synset.name(), \": \", synset.definition())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "state.v.01 :  express in words\n",
        "allege.v.01 :  report or maintain\n",
        "suppose.v.01 :  express a supposition\n",
        "read.v.02 :  have or contain a certain wording or form\n",
        "order.v.01 :  give instructions to or direct somebody to do something with authority\n",
        "pronounce.v.01 :  speak, pronounce, or utter in a certain way\n",
        "say.v.07 :  communicate or express nonverbally\n",
        "say.v.08 :  utter aloud\n",
        "say.v.09 :  state as one's opinion or judgement; declare\n",
        "say.v.10 :  recite or repeat a fixed text\n",
        "say.v.11 :  indicate\n",
        "aforesaid.s.01 :  being the one previously mentioned or spoken of\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I think 'state.v.01.' here best/most broadly represents what it is I'm searching for, and I'll thus use that."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "saidSynset = wn.synset(\"state.v.01\")\n",
      "said_hypernym_hyponyms = get_hyponym_names_from_hypernym(saidSynset)\n",
      "print(saidSynset, \"has\", len(said_hypernym_hyponyms), \"hyponyms\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Synset('state.v.01') has 376 hyponyms\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "saidRelatedWords = list(set([word for word in goldBugLemmas if word in said_hypernym_hyponyms]))\n",
      "print(saidRelatedWords)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['mouth', 'round', 'support', 'observe', 'pan', 'account', 'remark', 'drop', 'give', 'hold', 'assure', 'throw', 'condition', 'sign', 'represent', 'note', 'blame', 'will', 'counter', 'verify', 'comment', 'return', 'indicate', 'wish', 'chastise', 'notice', 'tell', 'premise', 'color', 'reason', 'promise', 'present', 'answer', 'ink', 'explain', 'say', 'propose', 'reply', 'raise', 'sentence', 'pretend', 'voice', 'claw', 'take']\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Okay. So this looks cool, but isn't what I expected. Because I chose to look at 'said' as it appears as a verb, I'll need to try to redo this list by only taking what WordNet determines to be verbs. As of now, I'm not entirely sure how I should do this though. I think I'll have to add in ``` pos=\"v\"``` into the function somewhere, but where specifically I do not know. I tried a few different things here, and I'll leave them in the notebook for your amusement, but in the end am going to stick with a non-ambiguous noun for this exercise."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def verb_only_collect_hyponym_lemma_names(synset, hyponynm_names):\n",
      "    for hyponym in synset(pos=\"v\").hyponyms(): # go through this synset's hyponym\n",
      "            for lemma in hyponym.lemmas(): # go through each hyponym's lemma\n",
      "                hyponynm_names.append(lemma.name()) # add this lemma name to our list\n",
      "    verb_only_collect_hyponym_lemma_names(hyponym, hyponynm_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def verb_only_collect_hyponym_lemma_names(synset, hyponynm_names):\n",
      "    for hyponym in synset.hyponyms(): # go through this synset's hyponym\n",
      "           if \".v\" in hyponym:\n",
      "                for lemma in hyponym.lemmas(): # go through each hyponym's lemma\n",
      "                    hyponynm_names.append(lemma.name()) # add this lemma name to our list\n",
      "    verb_only_collect_hyponym_lemma_names(hyponym, hyponynm_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def verb_only_get_hyponym_names_from_hypernym(synset):\n",
      "    names = []\n",
      "    for hypernym in synset.hypernyms():\n",
      "        verb_only_collect_hyponym_lemma_names(hypernym, names)\n",
      "    return sorted(set(names))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "said_verb_hypernym_hyponyms = get_hyponym_names_from_hypernym(saidSynset)\n",
      "print(saidSynset, \"has\", len(said_hypernym_hyponyms), \"hyponyms\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "argument of type 'Synset' is not iterable",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-59-2bfba30a2202>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msaid_verb_hypernym_hyponyms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_hyponym_names_from_hypernym\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaidSynset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaidSynset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"has\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaid_hypernym_hyponyms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"hyponyms\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-58-5ec0996f12b1>\u001b[0m in \u001b[0;36mget_hyponym_names_from_hypernym\u001b[1;34m(synset)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhypernym\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msynset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypernyms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mverb_only_collect_hyponym_lemma_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhypernym\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-57-4d8725fe65b5>\u001b[0m in \u001b[0;36mverb_only_collect_hyponym_lemma_names\u001b[1;34m(synset, hyponynm_names)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mverb_only_collect_hyponym_lemma_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msynset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyponynm_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhyponym\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msynset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyponyms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# go through this synset's hyponym\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m            \u001b[1;32mif\u001b[0m \u001b[1;34m\".v\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhyponym\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mlemma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhyponym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# go through each hyponym's lemma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mhyponynm_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# add this lemma name to our list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: argument of type 'Synset' is not iterable"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for synset in wn.synsets(\"tree\"):\n",
      "     print(synset.name(), \": \", synset.definition())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tree.n.01 :  a tall perennial woody plant having a main trunk and branches forming a distinct elevated crown; includes both gymnosperms and angiosperms\n",
        "tree.n.02 :  a figure that branches from a single root\n",
        "tree.n.03 :  English actor and theatrical producer noted for his lavish productions of Shakespeare (1853-1917)\n",
        "corner.v.02 :  force a person or an animal into a position from which he cannot escape\n",
        "tree.v.02 :  plant with trees\n",
        "tree.v.03 :  chase an animal up a tree\n",
        "tree.v.04 :  stretch (a shoe) on a shoetree\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treeSynset = wn.synset(\"tree.n.01\")\n",
      "tree_hypernym_hyponyms = get_hyponym_names_from_hypernym(treeSynset)\n",
      "print(treeSynset, \"has\", len(tree_hypernym_hyponyms), \"hyponyms\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Synset('tree.n.01') has 5030 hyponyms\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treeRelatedWords = list(set([word for word in goldBugLemmas if word in tree_hypernym_hyponyms]))\n",
      "print(treeRelatedWords)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['may', 'tree', 'shrub', 'myrtle', 'oak', 'palmetto', 'bramble', 'ti', 'box']\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There we go! This looks a bit more promissing than my adventure with 'said', but there are still a few words here that I'm unsure about, and so I think i'll make a concordonance to further check out the words 'box', 'ti', and 'may'."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "goldBugText = nltk.Text(goldBugLemmas)\n",
      "goldBugText.concordance(\"may\", 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Displaying 12 of 12 matches:\n",
        " by the fugitive from Charleston dust and fever may be found indeed the bristly palmetto but the wh\n",
        "n said I this is a very passable skull indeed I may say that it is a very excellent skull according\n",
        "carab\u00e6us in the world if it resembles it Why we may get up a very thrilling bit of superstition upo\n",
        "d not the slightest indication of fever But you may be ill and yet have no fever Allow me this once\n",
        "he sketch at which you had been looking and you may imagine my astonishment when I perceived in fac\n",
        "Pretty much but not altogether said Legrand You may have heard of one Captain Kidd I at once looked\n",
        "sole day of all the year in which it ha been or may be sufficiently cool for fire and that without \n",
        "e led me to take interest in such riddle and it may well be doubted whether human ingenuity can con\n",
        "uct an enigma of the kind which human ingenuity may not by proper application resolve In fact havin\n",
        "ng more than a mere guess The general use which may be made of the table is obvious but in this par\n",
        "n seven such arrangement the character being We may therefore assume that represents _t_ represents\n",
        "stance in the labor But this labor concluded he may have thought it expedient to remove all partici\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Well, 'may' here is certainly a verb, and I can only imagine that the 'may' found in tree's hypernyms was referring to the Month, so I will make sure to remove this word from my tree like words."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "goldBugText.concordance(\"ti\", 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Displaying 2 of 2 matches:\n",
        "d Mos feerd for to ventur pon dis limb berry far ti dead limb putty much all de way Did you say it w\n",
        " from your left Yes I nose dat nose all bout dat ti my lef hand what I chop de wood wid To be sure y\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I'm not sure in what extent 'ti' is supposed to relate to tree, but what is evident is that it belongs to Jupiter's diction and I don't wish to include it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "goldBugText.concordance(\"box\", 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Displaying 2 of 2 matches:\n",
        "perhaps that of the Bi-chloride of Mercury This box wa three foot and a half long three foot broad \n",
        "d were the idea of all We finally lightened the box by removing two third of it content when we wer\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, I don't think box applies here either.\n",
      "\n",
      "That being said, I'll now try to take those words our of my treeRelatedWords and make a new list to further work from:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treeRelatedWordsFiltered = [word for word in treeRelatedWords if word not in [\"may\", \"ti\",\"box\"]]\n",
      "print(treeRelatedWordsFiltered)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['tree', 'shrub', 'myrtle', 'oak', 'palmetto', 'bramble']\n"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "goldBugLemmasForTrees = [\"tree words\" if word in treeRelatedWordsFiltered else word for word in goldBugLemmas]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now we'll do a similar thing as we did with 'bug' to count and calculate the percent increase of our words found!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treeWordLemmaCount = goldBugLemmasForTrees.count(\"tree words\")\n",
      "treeTokenCount = goldBugWordTokensLowercase.count(\"tree\")\n",
      "print(\"The number of occurences of tree-like words in our lemma list is: \", treeWordLemmaCount, \"\\nThe number of occurences of 'tree' in our token list is: \", treeTokenCount)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The number of occurences of tree-like words in our lemma list is:  36 \n",
        "The number of occurences of 'tree' in our token list is:  25\n"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "differenceBetweenTreeCounts = treeWordLemmaCount - treeTokenCount\n",
      "percentageIncreaseOfTreeCounts = (differenceBetweenTreeCounts/treeTokenCount)*100\n",
      "print(\"By using hyponyms and hypernyms we were able to find \", percentageIncreaseOfTreeCounts, \"% more occurences of tree related words!\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "By using hyponyms and hypernyms we were able to find  44.0 % more occurences of tree related words!\n"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}